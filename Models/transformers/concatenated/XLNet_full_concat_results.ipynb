{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsNcwFIui_zf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking, GRU\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7p8GzO0hjME3",
    "outputId": "2e60bfa1-d936-41bd-fc23-b342f5283223"
   },
   "outputs": [],
   "source": [
    "drive.mount(\"/content/Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJHxaWy3jTVv"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/content/Drive/My Drive/LNLP/dataset.csv') # path to multi dataset\n",
    "x_dev0 = load(\"/content/Drive/My Drive/LNLP/Hierarchical/XLNet_full_concat/XLNet_dev.npy\", allow_pickle= True) # load the transformer output embeddinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DG6Ut08AjeSp"
   },
   "outputs": [],
   "source": [
    "x_train0_1 = load(\"/content/Drive/My Drive/LNLP/Hierarchical/XLNet_full_concat/XLNet_train_1.npy\", allow_pickle= True)\n",
    "x_train0_2 = load(\"/content/Drive/My Drive/LNLP/Hierarchical/XLNet_full_concat/XLNet_train_2.npy\", allow_pickle= True)\n",
    "x_train0_3 = load(\"/content/Drive/My Drive/LNLP/Hierarchical/XLNet_full_concat/XLNet_train_3.npy\", allow_pickle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7EAKA8zkDUo"
   },
   "outputs": [],
   "source": [
    "x_train0_A = np.concatenate((x_train0_1, x_train0_2))\n",
    "x_train0 = np.concatenate((x_train0_A, x_train0_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mXJA0kcKke4k",
    "outputId": "6381ef60-0b8e-4cb5-8eee-ef5c6d32e893"
   },
   "outputs": [],
   "source": [
    "dev = dataset.loc[dataset['split'] == 'dev']\n",
    "train = dataset.loc[dataset['split'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pi3UylaNlD8X"
   },
   "outputs": [],
   "source": [
    "y_train0 = []\n",
    "for i in range(train.shape[0]):\n",
    "  y_train0.append(train.loc[i,'label'])\n",
    "\n",
    "y_dev0 = []\n",
    "for i in range(dev.shape[0]):\n",
    "  y_dev0.append(dev.loc[i+32305,'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2FujyHKlLiV"
   },
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iS3FfqoWlNI4"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    Hierarchial Attention Layer as described by Hierarchical Attention Networks for Document Classification(2016)\n",
    "    - Yang et. al.\n",
    "    Source: https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "    Theano backend\n",
    "    \"\"\"\n",
    "    def __init__(self,attention_dim=200,return_coefficients=False,**kwargs):\n",
    "        # Initializer \n",
    "        self.supports_masking = True\n",
    "        self.return_coefficients = return_coefficients\n",
    "        self.init = initializers.get('glorot_uniform') # initializes values with uniform distribution\n",
    "        self.attention_dim = attention_dim\n",
    "        print(\"attention_dim\", self.attention_dim)\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Builds all weights\n",
    "        # W = Weight matrix, b = bias vector, u = context vector\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)),name='W')\n",
    "        # print(\"shape of Weight matrix W\",self.W.get_shape())\n",
    "        self.b = K.variable(self.init((self.attention_dim, )),name='b')\n",
    "        # print(\"shape of bias vector b\",self.b.get_shape())\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)),name='u')\n",
    "        # print(\"shape of context vector u\",self.u.get_shape())\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def _get_attention_weights(self, X):\n",
    "        \n",
    "        u_tw = K.tanh(K.dot(X, self.W))\n",
    "        tw_stimulus = K.dot(u_tw, self.u)\n",
    "\n",
    "        # Remove the last axis an apply softmax to the stimulus to\n",
    "        # get a probability.\n",
    "        tw_stimulus = K.squeeze(tw_stimulus, -1)\n",
    "        tw_stimulus = K.exp(tw_stimulus)\n",
    "        \n",
    "        # if mask is not None:\n",
    "        #     tw_stimulus *= K.cast(mask, K.floatx())\n",
    "\n",
    "        tw_stimulus /= K.cast(K.sum(tw_stimulus, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        att_weights = K.expand_dims(tw_stimulus)\n",
    "        # tw_stimulus = K.reshape(tw_stimulus, (-1, tw_stimulus.shape[1]))\n",
    "        # att_weights = K.softmax(tw_stimulus)\n",
    "\n",
    "        return att_weights\n",
    "\n",
    "    def call(self, hit, mask=None):\n",
    "        att_weights = self._get_attention_weights(hit)\n",
    "        print(\"Shape of att_weights\", att_weights.get_shape()) #(None, None, 1)\n",
    "        print(\"Shape of hit\", hit.get_shape()) #(None, None, 200)\n",
    "        # Reshape the attention weights to match the dimensions of X\n",
    "        # att_weights = K.reshape(att_weights, (None, None, 1))\n",
    "        # att_weights = K.repeat_elements(att_weights, hit.shape[-1], -1)\n",
    "\n",
    "        # Here, the actual calculation is done\n",
    "        uit = K.bias_add(K.dot(hit, self.W),self.b)\n",
    "        # print(\"shape of uit\",uit.get_shape())\n",
    "        uit = K.tanh(uit)\n",
    "        # print(\"shape of uit\",uit.get_shape())\n",
    "        \n",
    "        ait = K.dot(uit, self.u)\n",
    "        # print(\"shape of ait\",ait.get_shape(),ait)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "        ait = K.exp(ait)\n",
    "        \n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        # print(\"shape of hit and ait\",hit.get_shape(),ait.get_shape())\n",
    "        # print(hit,ait)\n",
    "        # print(\"att_weights\", (ait))\n",
    "        weighted_input = hit * ait\n",
    "        \n",
    "        if self.return_coefficients:\n",
    "            return [K.sum(weighted_input, axis=1), ait]\n",
    "        else:\n",
    "            return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \n",
    "        if self.return_coefficients:\n",
    "            return [(input_shape[0], input_shape[-1]), (input_shape[0], input_shape[-1], 1)]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]\n",
    "    #def predict_sentence_attention(self,X):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Tuzwnq7ilOQI",
    "outputId": "557b1010-a7e2-401f-f606-5c18733ef816"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "# model.add(AttentionLayer())\n",
    "text_input = Input(shape=(None,3072,), dtype='float32', name='text') #1 sent_input\n",
    "print(\"text input\",text_input)\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input) #2 sent_encoder\n",
    "print(\"l_mask\",l_mask)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.Bidirectional(GRU(200,return_sequences=True))(l_mask) #3 sent_gru\n",
    "encoded_text1 = layers.Bidirectional(GRU(200,return_sequences=True))(encoded_text) #4\n",
    "encoded_text2 = layers.Bidirectional(GRU(200,return_sequences=True))(encoded_text1)\n",
    "# out_dense = layers.Dense(200, activation='relu')(encoded_text1) #5 sent_dense\n",
    "sent_att,sent_coeffs, = AttentionLayer(400,return_coefficients=True,name='sent_attention')(encoded_text2) #6\n",
    "print(\"sent_att\",sent_att)\n",
    "print(\"sent_coeffs\",sent_coeffs)\n",
    "sent_drop = Dropout(0.5,name='sent_dropout')(sent_att)\n",
    "# And we add a softmax classifier on top\n",
    "out1 = layers.Dense(64, activation='relu')(sent_drop) #7 preds\n",
    "out = layers.Dense(1, activation='sigmoid')(out1)\n",
    "model = Model(text_input,out)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-K9IPdylTXP"
   },
   "outputs": [],
   "source": [
    "num_sequences = len(x_train0)\n",
    "batch_size = 32\n",
    "batches_per_epoch =  int(num_sequences/batch_size)\n",
    "#assert batch_size * batches_per_epoch == num_sequences\n",
    "num_features= 3072\n",
    "def train_generator():\n",
    "    x_list= x_train0\n",
    "    y_list =  y_train0\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(x_train0[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCUw15cMlrWO"
   },
   "outputs": [],
   "source": [
    "num_sequences_val = len(x_dev0)\n",
    "batch_size_val = 32\n",
    "batches_per_epoch_val = int(num_sequences_val/batch_size_val)\n",
    "#assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 3072\n",
    "def val_generator():\n",
    "    x_list= x_dev0\n",
    "    y_list =  y_dev0\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(x_dev0[:(b + 1) * batch_size_val][-batch_size_val:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Un45N6bPlt4z"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=2, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_BBDbtQlvh_"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RzUPC0cHlxJF",
    "outputId": "fdc2a420-5d79-473c-c960-136712db8a27"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator(), steps_per_epoch=batches_per_epoch, epochs=1,\n",
    "                    validation_data=val_generator(), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yEwkNXPlyZJ"
   },
   "outputs": [],
   "source": [
    "# x_test0 = load(\"BERT_test.npy\", allow_pickle = True)\n",
    "x_test0 = load(\"/content/Drive/My Drive/LNLP/Hierarchical/XLNet_full_concat/XLNet_test.npy\", allow_pickle= True)\n",
    "test = dataset.loc[dataset['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFbjzDUQ22jw"
   },
   "outputs": [],
   "source": [
    "#assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 3072\n",
    "def test_generator():\n",
    "    x_list= x_test0\n",
    "    y_list =  y_test0\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_test):\n",
    "            if(b == batches_per_epoch_test-1):\n",
    "              # longest_index = num_sequences_val - 1\n",
    "              longest_index = num_sequences_test - 1\n",
    "              timesteps = len(max(x_test0[:longest_index + 1][-batch_size_test:], key=len))\n",
    "              # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "              x_train = np.full((longest_index - b*batch_size_test, timesteps, num_features), -99.)\n",
    "              y_train = np.zeros((longest_index - b*batch_size_test,  1))\n",
    "              for i in range(longest_index - b*batch_size_test):\n",
    "                  li = b * batch_size_test + i\n",
    "                  # print(\"li\", li)\n",
    "                  # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                  x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                  y_train[i] = y_list[li]\n",
    "            else:\n",
    "                longest_index = (b + 1) * batch_size_test - 1\n",
    "                timesteps = len(max(x_test0[:(b + 1) * batch_size_test][-batch_size_test:], key=len))\n",
    "                # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "                x_train = np.full((batch_size_test, timesteps, num_features), -99.)\n",
    "                y_train = np.zeros((batch_size_test,  1))\n",
    "                for i in range(batch_size_test):\n",
    "                    li = b * batch_size_test + i\n",
    "                    # print(\"li\", li)\n",
    "                    # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                    x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                    y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mMsYzH4724U0",
    "outputId": "fb21ecaf-24b2-41d6-d620-6edfcfb1608c"
   },
   "outputs": [],
   "source": [
    "y_test0 = []\n",
    "for i in range(test.shape[0]):\n",
    "  y_test0.append(test.loc[i+33299,'label'])\n",
    "\n",
    "num_sequences_test = len(x_test0)\n",
    "batch_size_test = 32\n",
    "if(num_sequences_test%batch_size_test == 0):\n",
    "  batches_per_epoch_test = int(num_sequences_test/batch_size_test)\n",
    "else:\n",
    "  batches_per_epoch_test = int(num_sequences_test/batch_size_test) + 1\n",
    "#assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 3072\n",
    "model.evaluate_generator(test_generator(), steps= batches_per_epoch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GfJceEP03EBy"
   },
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_generator(), steps= batches_per_epoch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FFc10vW43GOD",
    "outputId": "65038b11-153a-408a-abf3-abac66fe0063"
   },
   "outputs": [],
   "source": [
    "y_pred = preds > 0.5\n",
    "ct=0\n",
    "for i in range(len(y_pred)):\n",
    "  if(y_pred[i] == y_test0[i]):\n",
    "    ct+=1\n",
    "\n",
    "print(ct/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHgdUfd53HpZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def metrics_calculator(preds, test_labels):\n",
    "    cm = confusion_matrix(test_labels, preds)\n",
    "    TP = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    for i in range(0,2):\n",
    "        summ = 0\n",
    "        for j in range(0,2):\n",
    "            if(i!=j):\n",
    "                summ=summ+cm[i][j]\n",
    "\n",
    "        FN.append(summ)\n",
    "    for i in range(0,2):\n",
    "        summ = 0\n",
    "        for j in range(0,2):\n",
    "            if(i!=j):\n",
    "                summ=summ+cm[j][i]\n",
    "\n",
    "        FP.append(summ)\n",
    "    for i in range(0,2):\n",
    "        TP.append(cm[i][i])\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(0,2):\n",
    "        precision.append(TP[i]/(TP[i] + FP[i]))\n",
    "        recall.append(TP[i]/(TP[i] + FN[i]))\n",
    "\n",
    "    macro_precision = sum(precision)/2\n",
    "    macro_recall = sum(recall)/2\n",
    "    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n",
    "    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n",
    "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n",
    "    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n",
    "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "asV93Qc-3NGM",
    "outputId": "bb76f631-929b-4e42-ddb5-e1401bf87677"
   },
   "outputs": [],
   "source": [
    "print(metrics_calculator(y_pred, y_test0[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1NQ_RbY3Qyz"
   },
   "outputs": [],
   "source": [
    "preds = model.predict_generator(val_generator(), steps= batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJ7ZgFB83VBh"
   },
   "outputs": [],
   "source": [
    "y_pred_dev = preds > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FhYgGL2B3WLY",
    "outputId": "6d770de2-1265-4674-9834-3163c76d951e"
   },
   "outputs": [],
   "source": [
    "ct=0\n",
    "for i in range(len(y_pred_dev)):\n",
    "  if(y_pred_dev[i] == y_dev0[i]):\n",
    "    ct+=1\n",
    "\n",
    "print(ct/len(y_pred_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "71ItHIqo3XU-",
    "outputId": "edc72001-9e1d-429f-e6b4-a91615eb96f5"
   },
   "outputs": [],
   "source": [
    "print(metrics_calculator(y_pred_dev, y_dev0[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdYSukkl3Yco"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# if not os.path.exists(os.path.join('..', 'h5.models')):\n",
    "#   os.mkdir(os.path.join('/content/Drive/My Drive/shared_by_vijit/LNLP/HAN/RoBERTa/', 'Roberta_gru_3_layer_attention'))\n",
    "model.save(os.path.join('/content/Drive/My Drive/LNLP/Hierarchical/XLNet_full_concat/', '', 'XGA_concat_epoch1_3.h5'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "XLNet_full_concat_results.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
