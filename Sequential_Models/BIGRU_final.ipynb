{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BIGRU_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWcymo_FWADn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b83a2fef-d042-4ab9-ef19-4dd8cc81ec5c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras import Sequential\n",
        "from keras.utils import Sequence\n",
        "from keras.layers import LSTM, Dense, Masking, GRU\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "np.random.seed(1337)# setting the random seed value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZULOpIvF4Yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ef8c417f-0d2d-4b72-d380-b3cfb53c3297"
      },
      "source": [
        "# Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2RgVj0jFrFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_dataset = \"drive/My Drive/dataset.csv\" # path to dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fwfyU5uCRR0K",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(path_dataset) # loading dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_1YqIPZ7L2K5",
        "colab": {}
      },
      "source": [
        "# path to transformer generated chunk embeddings eg. XLNet etc.\n",
        "path_transformer_chunk_embeddings_train = 'drive/My Drive/XLNet/XLNet_train.npy' \n",
        "path_transformer_chunk_embeddings_dev = 'drive/My Drive/XLNet/XLNet_dev.npy'\n",
        "path_transformer_chunk_embeddings_test = 'drive/My Drive/XLNet/XLNet_test.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c5rkC-VzPPBa",
        "colab": {}
      },
      "source": [
        "# loading the chunk embeddings\n",
        "x_train0 = load(path_transformer_chunk_embeddings_train, allow_pickle = True)\n",
        "x_dev0 = load(path_transformer_chunk_embeddings_dev, allow_pickle= True)\n",
        "x_test0 = load(path_transformer_chunk_embeddings_test, allow_pickle= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-aVSH_kLQ3pM",
        "colab": {}
      },
      "source": [
        "# loading the corresponding label for each case in dataset\n",
        "dev = dataset.loc[dataset['split'] == 'dev'] \n",
        "train = dataset.loc[dataset['split'] == 'train'] \n",
        "test = dataset.loc[dataset['split'] == 'test'] \n",
        "\n",
        "y_train0 = []\n",
        "for i in range(train.shape[0]):\n",
        "    y_train0.append(train.loc[i,'label'])  \n",
        "    \n",
        "y_dev0 = []\n",
        "for i in range(dev.shape[0]):\n",
        "    y_dev0.append(dev.loc[i+32305,'label'])\n",
        "\n",
        "y_test0 = []\n",
        "for i in range(test.shape[0]):\n",
        "    y_test0.append(test.loc[i+33299,'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PnMJO4OQcI5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "45d6ec33-52b2-4571-da40-767ae20242fc"
      },
      "source": [
        "from keras import layers\n",
        "# Input layer to convert into required tensor shape\n",
        "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
        "# Masking layer to mask the padded values\n",
        "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
        "# After masking we encoded the vector using 2 bidirectional GRU's\n",
        "encoded_text = layers.Bidirectional(GRU(100,return_sequences=True))(l_mask)\n",
        "encoded_text1 = layers.Bidirectional(GRU(100,))(encoded_text)\n",
        "# Added a dense layer after encoding\n",
        "out_dense = layers.Dense(30, activation='relu')(encoded_text1)\n",
        "# And we add a sigmoid classifier on top\n",
        "out = layers.Dense(1, activation='sigmoid')(out_dense)\n",
        "# At model instantiation, we specify the input and the output:\n",
        "model = Model(text_input, out)\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text (InputLayer)            (None, None, 768)         0         \n",
            "_________________________________________________________________\n",
            "masking_1 (Masking)          (None, None, 768)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 200)         521400    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 200)               180600    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                6030      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 708,061\n",
            "Trainable params: 708,061\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YgVbg80acVar",
        "colab": {}
      },
      "source": [
        "num_sequences = len(x_train0)\n",
        "batch_size = 32 \n",
        "batches_per_epoch =  int(num_sequences/batch_size)\n",
        "num_features= 768\n",
        "def train_generator(): # function to generate batches of corresponding batch size\n",
        "    x_list= x_train0\n",
        "    y_list =  y_train0\n",
        "    # Generate batches\n",
        "    while True:\n",
        "        for b in range(batches_per_epoch):\n",
        "            longest_index = (b + 1) * batch_size - 1\n",
        "            timesteps = len(max(x_train0[:(b + 1) * batch_size][-batch_size:], key=len))\n",
        "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
        "            y_train = np.zeros((batch_size,  1))\n",
        "            # padding the vectors with respect to the maximum sequence of each batch and not the whole training data\n",
        "            for i in range(batch_size):\n",
        "                li = b * batch_size + i\n",
        "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
        "                y_train[i] = y_list[li]\n",
        "            yield x_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vnGZeO1ieiAQ",
        "colab": {}
      },
      "source": [
        "num_sequences_val = len(x_dev0)\n",
        "batch_size_val = 32\n",
        "batches_per_epoch_val = int(num_sequences_val/batch_size_val)\n",
        "num_features= 768\n",
        "def val_generator():# Similar function to generate validation batches\n",
        "    x_list= x_dev0\n",
        "    y_list =  y_dev0\n",
        "    # Generate batches\n",
        "    while True:\n",
        "        for b in range(batches_per_epoch_val):\n",
        "            longest_index = (b + 1) * batch_size_val - 1\n",
        "            timesteps = len(max(x_dev0[:(b + 1) * batch_size_val][-batch_size_val:], key=len))\n",
        "            x_train = np.full((batch_size_val, timesteps, num_features), 0)\n",
        "            y_train = np.zeros((batch_size_val,  1))\n",
        "            # padding the vectors with respect to the maximum sequence of each batch and not the whole validation data\n",
        "            for i in range(batch_size_val):\n",
        "                li = b * batch_size_val + i\n",
        "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
        "                y_train[i] = y_list[li]\n",
        "            yield x_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MYZ7yr9mlYk_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f35a0985-c74e-44b6-f3ad-9a0b61a513ab"
      },
      "source": [
        "# Setting the callback and training the model\n",
        "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=2, verbose=2,\n",
        "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)\n",
        "\n",
        "model.fit_generator(train_generator(), steps_per_epoch=batches_per_epoch, epochs=3,\n",
        "                    validation_data=val_generator(), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1009/1009 [==============================] - 258s 256ms/step - loss: 0.4816 - acc: 0.7650 - val_loss: 0.6094 - val_acc: 0.7157\n",
            "Epoch 2/3\n",
            "1009/1009 [==============================] - 263s 261ms/step - loss: 0.4629 - acc: 0.7752 - val_loss: 0.5629 - val_acc: 0.7742\n",
            "Epoch 3/3\n",
            "1009/1009 [==============================] - 261s 259ms/step - loss: 0.4557 - acc: 0.7795 - val_loss: 0.5828 - val_acc: 0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa532aa2f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y3ET-FUAx8Su",
        "colab": {}
      },
      "source": [
        "def test_generator(): # function to generate batches of corresponding batch size\n",
        "    x_list= x_test0\n",
        "    y_list =  y_test0\n",
        "    # Generate batches\n",
        "    while True:\n",
        "        for b in range(batches_per_epoch_test):\n",
        "            if(b == batches_per_epoch_test-1): # An extra if else statement just to manage the last batch as it's size might not be equal to batch size \n",
        "              longest_index = num_sequences_test - 1\n",
        "              timesteps = len(max(x_test0[:longest_index + 1][-batch_size_test:], key=len))\n",
        "              x_train = np.full((longest_index - b*batch_size_test, timesteps, num_features), -99.)\n",
        "              y_train = np.zeros((longest_index - b*batch_size_test,  1))\n",
        "              for i in range(longest_index - b*batch_size_test):\n",
        "                  li = b * batch_size_test + i\n",
        "                  x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
        "                  y_train[i] = y_list[li]\n",
        "            else:\n",
        "                longest_index = (b + 1) * batch_size_test - 1\n",
        "                timesteps = len(max(x_test0[:(b + 1) * batch_size_test][-batch_size_test:], key=len))\n",
        "                x_train = np.full((batch_size_test, timesteps, num_features), -99.)\n",
        "                y_train = np.zeros((batch_size_test,  1))\n",
        "                # padding the vectors with respect to the maximum sequence of each batch and not the whole test data\n",
        "                for i in range(batch_size_test):\n",
        "                    li = b * batch_size_test + i\n",
        "                    x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
        "                    y_train[i] = y_list[li]\n",
        "            yield x_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i-HzpAFHdD-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d66bf71d-5718-4091-b4cd-12435f5c7794"
      },
      "source": [
        "num_sequences_test = len(x_test0)\n",
        "batch_size_test = 32\n",
        "batches_per_epoch_test = int(num_sequences_test/batch_size_test) + 1\n",
        "num_features= 768\n",
        "# evaluating on the test data\n",
        "model.evaluate_generator(test_generator(), steps= batches_per_epoch_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5188975930213928, 0.7671504020690918]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bko5x4jKnpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining a function which calculates various metrics such as micro and macro precision, accuracy and f1\n",
        "def metrics_calculator(preds, test_labels):\n",
        "    cm = confusion_matrix(test_labels, preds)\n",
        "    TP = []\n",
        "    FP = []\n",
        "    FN = []\n",
        "    for i in range(0,2):\n",
        "        summ = 0\n",
        "        for j in range(0,2):\n",
        "            if(i!=j):\n",
        "                summ=summ+cm[i][j]\n",
        "\n",
        "        FN.append(summ)\n",
        "    for i in range(0,2):\n",
        "        summ = 0\n",
        "        for j in range(0,2):\n",
        "            if(i!=j):\n",
        "                summ=summ+cm[j][i]\n",
        "\n",
        "        FP.append(summ)\n",
        "    for i in range(0,2):\n",
        "        TP.append(cm[i][i])\n",
        "    precision = []\n",
        "    recall = []\n",
        "    for i in range(0,2):\n",
        "        precision.append(TP[i]/(TP[i] + FP[i]))\n",
        "        recall.append(TP[i]/(TP[i] + FN[i]))\n",
        "\n",
        "    macro_precision = sum(precision)/2\n",
        "    macro_recall = sum(recall)/2\n",
        "    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n",
        "    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n",
        "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n",
        "    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n",
        "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b49_aClD2TFO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99d4646c-56e5-4111-dbbe-bb6e20fcf9cf"
      },
      "source": [
        "# getting the predicted labels on the test data\n",
        "preds = model.predict_generator(test_generator(), steps= batches_per_epoch_test)\n",
        "y_pred = preds > 0.5\n",
        "\n",
        "# Calculating all metrics on test data predicted label\n",
        "print(metrics_calculator(y_pred, y_test0[:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.7705673758865248, 0.7669248374829216, 0.7687417918381483, 0.7671503957783641, 0.7671503957783641, 0.7671503957783641)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLGnNSmqLahb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb209db8-22b6-4039-e691-078bb109b06b"
      },
      "source": [
        "# getting the predicted labels on the dev data\n",
        "preds = model.predict_generator(val_generator(), steps= batches_per_epoch_val)\n",
        "y_pred_dev = preds > 0.5\n",
        "\n",
        "# Calculating all metrics on dev data predicted label\n",
        "print(metrics_calculator(y_pred_dev, y_dev0[:-2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.7818560656979799, 0.78125, 0.7815529153535627, 0.78125, 0.78125, 0.78125)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ITN1ODSfa61U",
        "colab": {}
      },
      "source": [
        "# saving the trained model\n",
        "model.save('BIGRU_XLNet.h5')  # creates a HDF5 file 'BIGRU_XLNet.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NN5eSAN7R7As",
        "colab": {}
      },
      "source": [
        "# loading the model\n",
        "# model = load_model('BIGRU_XLNet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}